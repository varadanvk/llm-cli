[build-system]
requires = ["setuptools>=45", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "llm-chat-cli"
version = "0.0.4"
description = "A CLI tool for chatting with multiple LLM providers"
authors = [{name = "Varadan Kalkunte", email = "varadan.vk@gmail.com"}]
readme = "readme.md"
requires-python = ">=3.8"
classifiers = [
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Environment :: Console",
    "Topic :: Communications :: Chat",
    "Topic :: Scientific/Engineering :: Artificial Intelligence"
]
dependencies = [
    "groq",
    "openai",
    "anthropic",
    "tiktoken",
    "prompt_toolkit",
    "termcolor",
    "rich",
    "python-dotenv",
    "cerebras_cloud_sdk",
]

[project.scripts]
lmci = "llm_chat.cli:main"


[project.urls]
"Homepage" = "https://github.com/yourusername/llm_chat"
"Bug Tracker" = "https://github.com/yourusername/llm_chat/issues"

[tool.setuptools.packages.find]
where = ["src"]